#!/bin/bash

jobname="ambience"

rm -rf ALL_SLURMS
mkdir ALL_SLURMS ## store all the SLURMs created to this location

## FIXME here is where one can set the problem size --- like so 

nodes=$1
file=$2
work=$3
kway=$4
red=$5
split=$6



probSize=(200)
cores=(12)


func()
{
directive="#!/bin/bash\n\n#SBATCH --partition=$1\n#SBATCH --nodes=$2\n#SBATCH --ntasks-per-node=$3\n#SBATCH --job-name=$jobname\n#SBATCH --time=04:20:00\n#SBATCH --mail-user=rajaramr@buffalo.edu\n#SBATCH --output=result/%j.out\n#SBATCH --error=result/error_%j.out\n"
echo -e $directive
}


params="echo \"EXPERIMENT INPUT ----------------------\"\necho \"#filename \" \$1\necho \"#operation \" \$2\necho \"#kway \" \$3\necho \"#reducers \" \$4\necho \"#splits \" \$5\necho \"nodes \" \$SLURM_NNODES\necho \" cores \" \$6"


setup="module load java/1.6.0_22\nmodule load hadoop/2.5.1\nmodule load hbase/0.98.10.1\nmodule load myhadoop/0.30b\n"

setup1="export MH_SCRATCH_DIR=\$SLURMTMPDIR\nexport HADOOP_CONF_DIR=\$SLURM_SUBMIT_DIR/config-\$SLURM_JOBID\nexport HBASE_CONF_DIR=\$SLURM_SUBMIT_DIR/config-\$SLURM_JOBID\nmkdir hbase-logs-\$SLURM_JOBID\nexport MY_LOG_DIR=\$SLURM_SUBMIT_DIR/hbase-logs-\$SLURM_JOBID\n"

setup2="NPROCS=\`srun --nodes=\${SLURM_NNODES} bash -c 'hostname' |wc -l\`\n\$MH_HOME/bin/myhadoop-configure.sh >/dev/null\ncp \$HBASE_HOME/conf/hbase-env.sh-sample \$HBASE_CONF_DIR/hbase-env.sh\ncp \$HBASE_HOME/conf/hbase-site.xml-sample \$HBASE_CONF_DIR/hbase-site.xml\ncp \$HADOOP_CONF_DIR/slaves \$HBASE_CONF_DIR/regionservers\nNODE_A=\`cat  \$HADOOP_CONF_DIR/slaves | awk 'NR==1{print;exit}'\`\nNODE_B=\`cat  \$HADOOP_CONF_DIR/slaves | awk 'NR==2{print;exit}'\`\nNODE_C=\`cat  \$HADOOP_CONF_DIR/slaves | awk 'NR==3{print;exit}'\`\necho \$NODE_B > \$HBASE_CONF_DIR/backup-masters >/dev/null\nsed -i 's:NODE-A:'"\$NODE_A"':g' \$HBASE_CONF_DIR/hbase-site.xml\nsed -i 's:NODE-B:'"\$NODE_B"':g' \$HBASE_CONF_DIR/hbase-site.xml\nsed -i 's:NODE-C:'"\$NODE_C"':g' \$HBASE_CONF_DIR/hbase-site.xml\nsed -i 's:MY_HBASE_SCRATCH:'"\$SLURMTMPDIR"':g' \$HBASE_CONF_DIR/hbase-site.xml\nsed -i 's:MY_LOG_DIR:'"\$MY_LOG_DIR"':g' \$HBASE_CONF_DIR/hbase-env.sh\nls -l \$HADOOP_CONF_DIR >/dev/null\nsleep 15\n\$HADOOP_HOME/sbin/start-all.sh >/dev/null\nsleep 15\n\$HBASE_HOME/bin/start-hbase.sh --config=\$HBASE_CONF_DIR >/dev/null\nsleep 15\necho \"execution -f \$1 -i -99 -o \$2 -k \$3 -r \$4 -s \$5\"\n\$HADOOP_HOME/bin/hadoop --config \$HADOOP_CONF_DIR jar AMBIENCE.jar -f \$1 -i -99 -o \$2 -k \$3 -r \$4 -s \$5"

stop="\$HBASE_HOME/bin/stop-hbase.sh >/dev/null\n\$HADOOP_HOME/sbin/stop-all.sh >/dev/null\n\$MH_HOME/bin/myhadoop-cleanup.sh >/dev/null"


for core in "${cores[@]}"
do
   :
	func "general-compute" $nodes $core > SLURM_$nodes_$core
	echo -e $params >> SLURM_$nodes_$core
	echo -e $setup >> SLURM_$nodes_$core
	echo -e $setup1 >> SLURM_$nodes_$core
	echo -e $setup2 >> SLURM_$nodes_$core
	echo -e $stop >> SLURM_$nodes_$core
	sbatch SLURM_$nodes_$core $file $work $kway $red $split $core
done

mv SLURM* ALL_SLURMS/